{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caefcc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import spconv.pytorch as spconv\n",
    "import matplotlib.pyplot as plt\n",
    "import mytools\n",
    "import mymodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc5887d",
   "metadata": {},
   "source": [
    "# Select and load testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0732ce-7523-4ea2-8d0c-fa3e9e1690ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "58a54a5a-2fbc-4b21-b72f-99db81a56732",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "########################################\n",
    "# Select Energy (40 or 50 keV)\n",
    "Energy = 40\n",
    "# Select diff amount (H or L)\n",
    "Diff = 'H'\n",
    "########################################\n",
    "########################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d08e7a35-8a29-484b-b436-b42ee724bf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir</th>\n",
       "      <th>offset</th>\n",
       "      <th>diff</th>\n",
       "      <th>energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.9059989412649654, 0.3330733023117732, 0.26...</td>\n",
       "      <td>[1.8266272569888846, 0.22442560910839052, 0.04...</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.5710866775397127, -0.7536025709761512, -0....</td>\n",
       "      <td>[2.3028388182049855, 2.4187447290252235, -0.04...</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.4480694627678147, 0.21285006921436286, -0.8...</td>\n",
       "      <td>[1.352839218771808, 0.7031124760262129, 1.0990...</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.4873337835403693, 0.8520189791227151, 0.191...</td>\n",
       "      <td>[-1.6915320848865154, -1.5220214317304208, -1....</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.15061381983445352, 0.7777885525240438, 0.61...</td>\n",
       "      <td>[-0.7984063441458031, -0.6732262537600343, 1.2...</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 dir  \\\n",
       "0  [-0.9059989412649654, 0.3330733023117732, 0.26...   \n",
       "1  [-0.5710866775397127, -0.7536025709761512, -0....   \n",
       "2  [0.4480694627678147, 0.21285006921436286, -0.8...   \n",
       "3  [0.4873337835403693, 0.8520189791227151, 0.191...   \n",
       "4  [0.15061381983445352, 0.7777885525240438, 0.61...   \n",
       "\n",
       "                                              offset    diff energy  \n",
       "0  [1.8266272569888846, 0.22442560910839052, 0.04...  0.0443     40  \n",
       "1  [2.3028388182049855, 2.4187447290252235, -0.04...  0.0443     40  \n",
       "2  [1.352839218771808, 0.7031124760262129, 1.0990...  0.0443     40  \n",
       "3  [-1.6915320848865154, -1.5220214317304208, -1....  0.0443     40  \n",
       "4  [-0.7984063441458031, -0.6732262537600343, 1.2...  0.0443     40  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read pandas dataframe with all information about sparse testing tensors\n",
    "st_info = pd.read_pickle('/home/majd/sparse_testing_tensors_'+str(Energy)+'keV_'+Diff+'diff/sparse_tensor_info.pk')\n",
    "st_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "94fab85b-04f5-40fd-83e5-8d5a1e287953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W, D]: torch.Size([64, 120, 120, 120, 1])\n",
      "Shape of y: torch.Size([64, 3]) torch.float32\n",
      "Offsets:  torch.Size([64, 3])\n",
      "Voxel grid shape:  torch.Size([120, 120, 120])\n"
     ]
    }
   ],
   "source": [
    "# Make custom dataset\n",
    "MyDataset = mytools.CustomDataset(dir_loc='/home/majd/sparse_testing_tensors_'+str(Energy)+'keV_'+Diff+'diff/', st_info=st_info)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 64\n",
    "test_dataloader = DataLoader(MyDataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Print tensor shapes\n",
    "for X_plot, y_plot, offset_plot in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W, D]: {X_plot.shape}\")\n",
    "    print(f\"Shape of y: {y_plot.shape} {y_plot.dtype}\")\n",
    "    print(\"Offsets: \", offset_plot.shape)\n",
    "    break\n",
    "    \n",
    "#Record shape of voxel grid\n",
    "grid_shape = X_plot.shape[1:4]\n",
    "print(\"Voxel grid shape: \" , grid_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821bc73d-91a7-4a8f-a04b-398ea6c7bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an example as a sanity check\n",
    "\n",
    "# x/y/z length being kept in cm\n",
    "eff_l = mytools.voxel_grid['eff_l']\n",
    "# Voxel size in cm\n",
    "vox_l = mytools.voxel_grid['vox_l']\n",
    "\n",
    "#Convert to dense, reshape and convert to numpy\n",
    "X_plot = X_plot.to_dense().reshape(-1, 1, 120, 120, 120).numpy()\n",
    "\n",
    "index = 2\n",
    "mytools.plot_tensor_dir(tensor = X_plot[index], start = offset_plot[index].numpy(), direction = y_plot[index].numpy(), eff_l=eff_l, vox_l=vox_l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ff2c4-af7b-4e73-8c59-7368e3fe92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_plot[4].flatten() > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800d185-0706-4e08-b007-e21c6988b963",
   "metadata": {},
   "source": [
    "# Test HSCDC CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b63c41-a17b-47f5-9ad0-e9273fcd3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_HSCDC = torch.load('../3D_Heteroscedastic_Convnet_models/3D_HSCDC.pt').to(device)\n",
    "\n",
    "# Obtain predictions and Labels\n",
    "v_pred_HSCDC, K_pred_HSCDC, v_true_HSCDC, off_true_HSCDC = mytools.test_HSCDC(test_dataloader,model_HSCDC,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f49946-dcd6-45e3-b70d-f7524bedd8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the predicted kappa values\n",
    "plt.hist(K_pred_HSCDC.flatten().numpy(), density=True, histtype='step')\n",
    "plt.axvline(np.mean(K_pred_HSCDC.flatten().numpy()),label=\"Mean\")\n",
    "plt.xlabel(\"Predicted K\")\n",
    "print(np.mean(K_pred_HSCDC.flatten().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f74b8-9e24-41df-9837-b5930f0a4f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cosine similarity loss using the mean predictions from the HSCDC model\n",
    "HSCDC_Loss = mytools.CSloss(v_pred_HSCDC, v_true_HSCDC)\n",
    "HSCDC_Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0667ac0-474c-4074-aaa0-cc5c9f74d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compute the Loss versus efficiency cuts in K_pred (the uncertainty prediction in the HSCDC model)\n",
    "CS = nn.CosineSimilarity()\n",
    "\n",
    "# Percent of data that is cut\n",
    "eff = np.arange(0,90,1)\n",
    "# Coresponding percentiles\n",
    "pers = np.percentile(K_pred_HSCDC,eff)\n",
    "\n",
    "# Compute loss at each percentile\n",
    "eff_loss = []\n",
    "# Compute Head/Taill eff at each percentile\n",
    "HT_eff = []\n",
    "# Compute axial performance at each percentile\n",
    "AP = []\n",
    "\n",
    "for per in pers:\n",
    "    \n",
    "    T_vals = (K_pred_HSCDC >= per).flatten()\n",
    "    v_pred_cut = v_pred_HSCDC[T_vals]\n",
    "    v_true_cut = v_true_HSCDC[T_vals]\n",
    "    \n",
    "    eff_loss += [mytools.CSloss(v_pred_cut, v_true_cut)]\n",
    "    \n",
    "    vals = CS(v_pred_cut,v_true_cut)\n",
    "    HT_eff += [torch.sum(vals>0).item() / len(vals)]\n",
    "    AP += [torch.mean(-1.0*torch.abs(CS(v_pred_cut,v_true_cut)))]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931279e0-da6e-48d2-8e2b-9306909611c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how the predictions can be improved by cutting on Kappa\n",
    "plt.plot(eff,eff_loss, label = \"HSCDC CNN\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Percent Cut\")\n",
    "plt.ylabel(\"Cosine Similairity Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672003e-55a1-44d7-8264-9e3a89d8a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how the Head/Tail efficiency can be improved by cutting on Kappa\n",
    "plt.plot(eff,HT_eff, label = \"HSCDC CNN\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Percent Cut\")\n",
    "plt.ylabel(\"Head Tail Efficiency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6cf68e-6d5b-402e-8bf3-8cbc28feab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how the axial performance can be improved by cutting on Kappa\n",
    "plt.plot(eff,AP, label = \"HSCDC CNN\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Percent Cut\")\n",
    "plt.ylabel(\"Axial Performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1469bd0c-b5ba-43c9-9cb4-6d0578da91cf",
   "metadata": {},
   "source": [
    "# Test Regular CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf78e11-bc66-4074-af63-c069328e4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the regular CNN model\n",
    "model_CNN = torch.load('../3D_Heteroscedastic_Convnet_models/3D_CNN.pt').to(device)\n",
    "# Obtain predictions and labels\n",
    "v_pred_CNN, v_true_CNN, off_true_CNN = mytools.test_CNN(test_dataloader,model_CNN,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a534b9a-45eb-436c-84dd-e803fcc15e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cosine similairity loss, we cannot make efficiency cuts here\n",
    "CNN_Loss = mytools.CSloss(v_pred_CNN, v_true_CNN)\n",
    "CNN_Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83038b24-8bec-4127-9838-f6f5698e02de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the axial cosine similairity loss, we cannot make efficiency cuts here\n",
    "CNN_AP_loss = torch.mean(-1.0*torch.abs(CS(v_pred_CNN,v_true_CNN)))\n",
    "CNN_AP_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e4f7b-ac90-45ff-a699-5545dc5e0a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Head/Tail efficiency, we cannot make efficiency cuts here\n",
    "vals = CS(v_pred_CNN,v_true_CNN)\n",
    "CNN_HT_eff = torch.sum(vals>0).item() / len(vals)\n",
    "CNN_HT_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17cd12c-bff2-4a0a-94fe-3fbf5912271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eff,eff_loss, label = \"HSCDC CNN\")\n",
    "plt.scatter([0],[CNN_Loss], marker=\"x\", color = 'r', label = \"Regular CNN\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Percent Cut\")\n",
    "plt.ylabel(\"Cosine Similairity Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb86fac1-28eb-463d-ba3c-608b798f1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eff,AP, label = \"HSCDC CNN\")\n",
    "plt.scatter([0],[CNN_AP_loss], marker=\"x\", color = 'r', label = \"Regular CNN\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Percent Cut\")\n",
    "plt.ylabel(\"Axial Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a19f8-3085-4e30-93b2-84e17c965f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eff,HT_eff, label = \"HSCDC CNN\")\n",
    "plt.scatter([0],[CNN_HT_eff], marker=\"x\", color = 'r', label = \"Regular CNN\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Percent Cut\")\n",
    "plt.ylabel(\"Head Tail Efficiency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515cfab-493d-4596-ace9-a33c71ae85fb",
   "metadata": {},
   "source": [
    "# Test Non-ML algorithim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a153c2-61bb-4a3a-bf9b-e773664ad251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the non-ML model\n",
    "model_NML = mymodels.NML\n",
    "\n",
    "# x/y/z length being kept in cm\n",
    "eff_l= mytools.voxel_grid['eff_l']\n",
    "# Voxel size in cm\n",
    "vox_l = mytools.voxel_grid['vox_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555e60a-653a-4772-a55a-d51514f535bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy sparse tensor info dataframe\n",
    "NML_info = st_info.copy()\n",
    "# Promote index to column\n",
    "NML_info = NML_info.reset_index()\n",
    "\n",
    "# Add position and charge information for each row\n",
    "NML_info[\"positions\"] = NML_info.apply(lambda row: torch.load('/home/majd/sparse_testing_tensors_'+str(Energy)+'keV_'+Diff+'diff/'+ 'sparse_recoils_' + str(row['index']) + '.pt').type(torch.FloatTensor).coalesce().indices().int().numpy()*vox_l-eff_l, axis=1)\n",
    "NML_info[\"charges\"] = NML_info.apply(lambda row: torch.load('/home/majd/sparse_testing_tensors_'+str(Energy)+'keV_'+Diff+'diff/'+ 'sparse_recoils_' + str(row['index']) + '.pt').type(torch.FloatTensor).coalesce().values().flatten().numpy()*1.0, axis=1)\n",
    "\n",
    "NML_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92755b46-5a46-4eb1-8901-6343bee86273",
   "metadata": {},
   "source": [
    "## Test NML model with standard parameters and without cheating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f9cf8-31f7-42d2-b28e-ebf2973963e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true and predicted directions\n",
    "v_pred_NML, v_true_NML, off_true_NML = mytools.test_NML(NML_info, model_NML, cheat=False)\n",
    "\n",
    "#Compute efficiency and Loss\n",
    "# In this method, an efficency cut must be made as SVD can fail if it is not given >= 2 points\n",
    "NML_eff = len(v_pred_NML)/len(NML_info)\n",
    "NML_Loss = mytools.CSloss(torch.Tensor(v_pred_NML), torch.Tensor(v_true_NML))\n",
    "    \n",
    "print(NML_Loss, NML_eff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f96f2c-d154-415a-a66c-18ebe1e3a39d",
   "metadata": {},
   "source": [
    "## Test NML model with standard parameters and with cheating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd60ef-44bc-4222-b7e1-ec7cdf8050d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true and predicted directions\n",
    "v_pred_NML_cheat, v_true_NML_cheat, off_true_NML_cheat = mytools.test_NML(NML_info, model_NML, cheat=True)\n",
    "\n",
    "#Compute efficiency and Loss\n",
    "# In this method, an efficency cut must be made as SVD can fail if it is not given >= 2 points\n",
    "NML_eff_cheat = len(v_pred_NML_cheat)/len(NML_info)\n",
    "NML_Loss_cheat = mytools.CSloss(torch.Tensor(v_pred_NML_cheat), torch.Tensor(v_true_NML_cheat))\n",
    "    \n",
    "print(NML_Loss_cheat, NML_eff_cheat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5aafba-ca9b-4065-9529-f89b0744d381",
   "metadata": {},
   "source": [
    "## Test NML model with parameters tuned on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca19ccc-562d-4338-9149-95b4f6c23fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuned_cheat = pd.read_pickle('../tune_NML_model_coarse/tune_NML_'+str(Energy)+'keV_'+Diff+'diff_cheat-'+str(True)+'.pk')\n",
    "df_tuned = pd.read_pickle('../tune_NML_model_coarse/tune_NML_'+str(Energy)+'keV_'+Diff+'diff_cheat-'+str(False)+'.pk')\n",
    "\n",
    "#Only consider cases with over 10% efficiency\n",
    "df_tuned_cheat = df_tuned_cheat.loc[df_tuned_cheat.eff > 0.1].reset_index(drop = True)\n",
    "df_tuned = df_tuned.loc[df_tuned.eff > 0.1].reset_index(drop = True)\n",
    "\n",
    "\n",
    "min_tuned_cheat = df_tuned_cheat[['Loss']].idxmin()\n",
    "min_tuned = df_tuned[['Loss']].idxmin()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8f572-e670-4a8d-b888-b05836f12a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_tuned_cheat = df_tuned_cheat.iloc[min_tuned_cheat].Loss.item()\n",
    "Eff_tuned_cheat = df_tuned_cheat.iloc[min_tuned_cheat].eff.item()\n",
    "Loss_tuned = df_tuned.iloc[min_tuned].Loss.item()\n",
    "Eff_tuned = df_tuned.iloc[min_tuned].eff.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a20bf3-7220-4750-9167-43a9a90bf092",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Loss_tuned_cheat,Loss_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5829dc-6ac4-4491-ad11-47e248a39ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuned_cheat.iloc[min_tuned_cheat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf3c61-0f65-4c25-afbc-52effd030263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuned.iloc[min_tuned]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb931843-fca0-45b6-b4f7-cec07de136d5",
   "metadata": {},
   "source": [
    "# Test NML2 model with tuned epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f9c63-acb4-452b-b854-fc3ba8af7de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NML2 = pd.read_pickle('../tune_NML_model/tune_NML2_'+str(Energy)+'keV_'+Diff+'diff.pk')\n",
    "NML2_tuned = df_NML2[['Loss']].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba73eb7-e08b-41e1-bd5e-efcad82d64cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NML2_loss = df_NML2.iloc[NML2_tuned].Loss.item()\n",
    "NML2_eps = df_NML2.iloc[NML2_tuned].epsilon.item()\n",
    "\n",
    "print(\"The Cossine Similairity Loss is: \", NML2_loss)\n",
    "print(\"The tunes epsilon is: \", NML2_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a37eca-31d4-41b0-95c8-b5a6abcc7337",
   "metadata": {},
   "source": [
    "# Plot final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989b8626-0555-4e5c-a1c8-6fc3a7542aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the performance of the NML methods alongside the convnets\n",
    "\n",
    "plt.plot(eff,eff_loss, label = \"HSCDC CNN\")\n",
    "plt.scatter([0],[CNN_Loss], marker=\"D\", color = 'r', label = \"Regular CNN\")\n",
    "\n",
    "# Double plot as a has to format the legend properly\n",
    "plt.scatter([100*(1-NML_eff)], [NML_Loss], marker='o', color = 'orange', label = \"Non-ML standard\")\n",
    "plt.errorbar([100*(1-NML_eff)], [NML_Loss], yerr=[ np.abs(NML_Loss-NML_Loss_cheat) ], uplims=[1], fmt='o', color = 'orange')\n",
    "\n",
    "# Double plot as a has to format the legend properly\n",
    "plt.scatter([100*(1-Eff_tuned)], [Loss_tuned], marker='*', color = 'k', label = \"Non-ML tuned\")\n",
    "plt.errorbar([100*(1-Eff_tuned)], [Loss_tuned], yerr=[ np.abs(Loss_tuned-Loss_tuned_cheat) ], uplims=[1], fmt='*', color = 'k')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Percent Cut\")\n",
    "plt.ylabel(\"Cosine Similairity Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f141e5e-9690-4f38-8f4f-10dcea009270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the performance of the NML2 methods alongside the convnets\n",
    "\n",
    "\n",
    "plt.plot(eff,1+np.array(eff_loss), label = \"HCN\")\n",
    "plt.scatter([0],[1+CNN_Loss], marker=\"D\", color = 'r', label = \"RCN\")\n",
    "\n",
    "plt.axhline(1+NML2_loss,color = 'k', label = \"Best-Expected\")\n",
    "int_id = idx = (np.abs(np.array(eff_loss) - NML2_loss)).argmin()\n",
    "plt.axvline(eff[int_id],color = 'k',ls='--', label=str(eff[int_id])+\"% efficiency cut\")\n",
    "\n",
    "# Double plot as a has to format the legend properly\n",
    "plt.scatter([100*(1-NML_eff)], [1+NML_Loss], marker='o', color = 'orange', label = \"Non-ML standard\")\n",
    "plt.errorbar([100*(1-NML_eff)], [1+NML_Loss], yerr=[ np.abs(NML_Loss-NML_Loss_cheat) ], uplims=[1], fmt='o', color = 'orange')\n",
    "\n",
    "# Double plot as a has to format the legend properly\n",
    "plt.scatter([100*(1-Eff_tuned)], [1+Loss_tuned], marker='*', color = 'k', label = \"Non-ML tuned\")\n",
    "plt.errorbar([100*(1-Eff_tuned)], [1+Loss_tuned], yerr=[ np.abs(Loss_tuned-Loss_tuned_cheat) ], uplims=[1], fmt='*', color = 'k')\n",
    "\n",
    "\n",
    "plt.legend( fontsize=12)\n",
    "plt.xlabel(\"Efficiency Cut [%]\", fontsize=18)\n",
    "plt.ylabel(\"Cosine Distance Loss\", fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.savefig(str(Energy)+\"keV_\"+Diff+\"Diff.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981fe0e6-7c5f-4527-9ebc-240f6a7039da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the axial performance of the NML2 methods alongside the convnets\n",
    "\n",
    "\n",
    "plt.plot(eff,AP, label = \"HCN\")\n",
    "plt.scatter([0],[CNN_AP_loss], marker=\"D\", color = 'r', label = \"RCN\")\n",
    "\n",
    "plt.axhline(NML2_loss,color = 'k', label = \"Non-ML2\")\n",
    "int_id = idx = (np.abs(np.array(AP) - NML2_loss)).argmin()\n",
    "#plt.axvline(eff[int_id],color = 'k',ls='--',label=str(eff[int_id])+\" percent cut\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Efficiency Cut [%]\")\n",
    "plt.ylabel(\"Axial Cosine Similairity Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc685f-bf6b-4913-be53-d7f9bb3df821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypt",
   "language": "python",
   "name": "mypt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "e137a2665c242313c11d472736bb1efbdaf7608c607fce3fc4f47a32817024ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
